# -*- coding: utf-8 -*-
"""image_cropping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aFRy9n4l7gCLhuGURut1m7VnTd7zk-Fy
"""

import numpy as np
import cv2
import dlib
from PIL import Image
!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
!bunzip2 "shape_predictor_68_face_landmarks.dat.bz2"  # unzip the file

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

from google.colab import files

uploaded = files.upload()

local = []
for fn in uploaded.keys():
  local.append(fn)
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

predictor_path = 'shape_predictor_68_face_landmarks.dat'  # path of data

#initializes dlibâ€™s pre-trained face detector based on a modification to the standard Histogram of Oriented Gradients + Linear SVM method for object detection.
detector = dlib.get_frontal_face_detector() 
#loads the facial landmark predictor using the path
predictor = dlib.shape_predictor(predictor_path)

img = cv2.imread('/content/IMG-20191007-WA0007[82] (3).jpg')
gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  # convert color image to grayscale image
rects = detector(gray_image) # detect faces in the grayscale image

def rect_to_bb(rect):
	# take a bounding predicted by dlib and convert it
	# to the format (x, y, w, h) as we would normally do
	# with OpenCV
	x = rect.left()
	y = rect.top()
	w = rect.right() - x
	h = rect.bottom() - y

	# return a tuple of (x, y, w, h)
	return (x, y, w, h)

def shape_to_np(shape, dtype = int):
  
  coords = np.zeros((68, 2), dtype=dtype)
  for i in range(0,68):
    coords[i] = (shape.part(i).x, shape.part(i).y)
  return coords # loop over the 68 facial landmarks and convert them

def forehead_dist(coords):
  d = (np.sum(coords[42:47,1]) - np.sum(coords[36:41,1]))/ 6
  return d

for (i, rect) in enumerate(rects):
	
	shape = predictor(gray_image, rect)
	shape = shape_to_np(shape)
  
	# convert dlib's rectangle to a OpenCV-style bounding box
	# [i.e., (x, y, w, h)], then draw the face bounding box
	(x, y, w, h) = rect_to_bb(rect)
	d = forehead_dist(shape)
	d_t_y = int(np.sum(shape[42:47,1])/6 - 0.6*d)
	d_l_x, d_l_y = shape[0]
	d_b_x,d_b_y = shape[8]
	d_r_x,d_l_y = shape[16]
	image = img[d_t_y:d_b_y,d_l_x:d_r_x]  # croppped image
if(len(rects) > 0):
	plt.imshow(image)
else:
	print('Landmark is not detected')
	plt.imshow(img)

